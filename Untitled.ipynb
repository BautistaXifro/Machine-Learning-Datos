{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'catboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4e76f878c4f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcatboost\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'catboost'"
     ]
    }
   ],
   "source": [
    "import catboost as cat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Gráficos\n",
    "# ==============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Preprocesado y modelado\n",
    "# ==============================================================================\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import multiprocessing\n",
    "\n",
    "# Configuración warnings\n",
    "# =================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv( \"../Training.csv\" )\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5d737e4d84ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Total_Amount_Currency'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'JPY'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Total_Amount'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Total_Amount'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.0096\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Total_Amount_Currency'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'JPY'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Total_Amount_Currency'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'USD'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Total_Amount_Currency'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'EUR'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Total_Amount'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Total_Amount'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1.17\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Total_Amount_Currency'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'EUR'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Total_Amount_Currency'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'USD'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.loc[df['Total_Amount_Currency'] == 'JPY', 'Total_Amount'] = df['Total_Amount']*0.0096\n",
    "df.loc[df['Total_Amount_Currency'] == 'JPY', 'Total_Amount_Currency'] = 'USD'\n",
    "\n",
    "df.loc[df['Total_Amount_Currency'] == 'EUR', 'Total_Amount'] = df['Total_Amount']*1.17\n",
    "df.loc[df['Total_Amount_Currency'] == 'EUR', 'Total_Amount_Currency'] = 'USD'\n",
    "\n",
    "df.loc[df['Total_Amount_Currency'] == 'AUD', 'Total_Amount'] = df['Total_Amount']*0.70\n",
    "df.loc[df['Total_Amount_Currency'] == 'AUD', 'Total_Amount_Currency'] = 'USD'\n",
    "\n",
    "df.loc[df['Total_Amount_Currency'] == 'GBP', 'Total_Amount'] = df['Total_Amount']*1.29\n",
    "df.loc[df['Total_Amount_Currency'] == 'GBP', 'Total_Amount_Currency'] = 'USD'\n",
    "df.dropna(inplace = True)\n",
    "df['Opportunity_Created_Date'] = pd.to_datetime(df['Opportunity_Created_Date'],errors='coerce')\n",
    "df[\"Year Created\"] = df[\"Opportunity_Created_Date\"].dt.year\n",
    "df[\"Month Created\"] =df[\"Opportunity_Created_Date\"].dt.month\n",
    "df[\"Expensive\"] = np.where(df[\"Total_Taxable_Amount\"] >= 80000, 1, 0)\n",
    "df['Planned_Delivery_Start_Date'] = pd.to_datetime(df['Planned_Delivery_Start_Date'],errors='coerce')\n",
    "df['Planned_Delivery_End_Date'] = pd.to_datetime(df['Planned_Delivery_End_Date'],errors='coerce')\n",
    "df = df[df[\"Total_Amount\"] > 0]\n",
    "df[\"Total_Amount\"] = np.log(df[\"Total_Amount\"])\n",
    "entrenamiento_by_region = df.groupby(\"Region\").agg({\"Stage\" : \"count\"})\n",
    "entrenamiento_by_region.rename(columns = {\"Stage\" : \"Amount of Cases\"}, inplace = True)\n",
    "entrenamiento_won_by_region = df[df[\"Stage\"] == \"Closed Won\"].groupby(\"Region\").agg({\"Stage\" : \"count\"})\n",
    "entrenamiento_won_by_region.rename(columns = {\"Stage\" : \"Cases won\"}, inplace = True)\n",
    "\n",
    "entrenamiento_won_by_region[\"percentage\"] = (entrenamiento_won_by_region[\"Cases won\"] / entrenamiento_by_region[\"Amount of Cases\"]) * 100\n",
    "df = df.merge(entrenamiento_won_by_region, on = \"Region\")\n",
    "df[\"Años en entregar\"] = df[\"Delivery_Year\"] - df[\"Year Created\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Source \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()\n",
    "df1 = df.copy()\n",
    "df1[\"Stage\"] = np.where(df1[\"Stage\"] == \"Closed Won\", 1, 0)\n",
    "df1[\"Stage\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Product_Name\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_df = df[['Opportunity_ID', \"Total_Amount\", \"Años en entregar\",\"Month Created\", \"Product_Name\", \"Opportunity_Owner\", 'Stage' ]].rename(columns={'Stage': 'Decision'})\n",
    "short_df = short_df[ (short_df['Decision'] == 'Closed Won') | (short_df['Decision'] == 'Closed Lost') ]\n",
    "short_df['Decision'] = np.where(short_df['Decision'] == 'Closed Won',1,0)\n",
    "short_df.set_index('Opportunity_ID', inplace = True)\n",
    "\n",
    "\n",
    "short_df.describe()\n",
    "short_df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_df[\"Product_Name\"] = np.where(short_df.groupby('Product_Name')[\"Product_Name\"].transform(len) > 5, short_df[\"Product_Name\"], \"Other\")\n",
    "short_df[\"Product_Name\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_df[\"Opportunity_Owner\"] = np.where(short_df.groupby('Opportunity_Owner')[\"Opportunity_Owner\"].transform(len) > 5, short_df[\"Opportunity_Owner\"], \"Other\")\n",
    "short_df[\"Opportunity_Owner\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_encoded_product = short_df.groupby(\"Product_Name\")[\"Decision\"].mean().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_df[\"Product_Name\"] = short_df[\"Product_Name\"].map(mean_encoded_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_encoded_owner = short_df.groupby(\"Opportunity_Owner\")[\"Decision\"].mean().to_dict()\n",
    "short_df[\"Opportunity_Owner\"] = short_df[\"Opportunity_Owner\"].map(mean_encoded_owner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_encoded_source = short_df.groupby(\"Source \")[\"Decision\"].mean().to_dict()\n",
    "short_df[\"Source \"] = short_df[\"Source \"].map(mean_encoded_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_df[\"Account_Owner\"] = np.where(short_df.groupby('Account_Owner')[\"Account_Owner\"].transform(len) > 5, short_df[\"Account_Owner\"], \"Other\")\n",
    "short_df[\"Account_Owner\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_encoded_accountowner = short_df.groupby(\"Account_Owner\")[\"Decision\"].mean().to_dict()\n",
    "short_df[\"Account_Owner\"] = short_df[\"Account_Owner\"].map(mean_encoded_accountowner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_df[\"Account_Type\"] = np.where(short_df.groupby('Account_Type')[\"Account_Type\"].transform(len) > 5, short_df[\"Account_Type\"], \"Other\")\n",
    "short_df[\"Account_Type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_encoded_acc = short_df.groupby(\"Account_Type\")[\"Decision\"].mean().to_dict()\n",
    "short_df[\"Account_Type\"] = short_df[\"Account_Type\"].map(mean_encoded_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_df[\"Account_Name\"] = np.where(short_df.groupby('Account_Name')[\"Account_Name\"].transform(len) > 5, short_df[\"Account_Name\"], \"Other\")\n",
    "mean_encoded_accow = short_df.groupby(\"Account_Name\")[\"Decision\"].mean().to_dict()\n",
    "short_df[\"Account_Name\"] = short_df[\"Account_Name\"].map(mean_encoded_accow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_encoded_accow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_encoded_bur = short_df.groupby(\"Bureaucratic_Code\")[\"Decision\"].mean().to_dict()\n",
    "short_df[\"Bureaucratic_Code\"] = short_df[\"Bureaucratic_Code\"].map(mean_encoded_bur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_df[\"Bureaucratic_Code\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# División de los datos en train y test\n",
    "# ==============================================================================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                        short_df.drop(columns = 'Decision'),\n",
    "                                        short_df['Decision'],\n",
    "                                        random_state = 123,\n",
    "                                        test_size = 0.3\n",
    "                                    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prep1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# División de los datos en train y test\n",
    "# ==============================================================================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                        short_df.drop(columns = 'Decision'),\n",
    "                                        short_df['Decision'],\n",
    "                                        random_state = 123\n",
    "                                    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CATBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cat.CatBoostRegressor(learning_rate = 0.0075, verbose = True, random_seed = 123, loss_function = \"RMSE\", num_boost_round = 1500, max_depth = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d768f88d541e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = log_loss(y_test, preds)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureImportance = pd.DataFrame(fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureImportance[\"Attribute\"] = model.feature_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureImportance.columns = [\"Value\", \"Attribute\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureImportance.set_index(\"Attribute\").sort_values(by = \"Value\", ascending = False).plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADABOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm.sklearn import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "adaModel = AdaBoostRegressor(base_estimator = cat.CatBoostRegressor(learning_rate = 0.0075, verbose = True, random_seed = 123, loss_function = \"RMSE\", num_boost_round = 1500, max_depth = 8), learning_rate = 0.01, n_estimators = 55, random_state = 123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaModel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = adaModel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = log_loss(y_test, preds)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaModel.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = adaModel.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureImportance = pd.DataFrame(fi)\n",
    "featureImportance[\"Attribute\"] = X_train.columns\n",
    "featureImportance.columns = [\"Value\", \"Attribute\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureImportance.set_index(\"Attribute\").sort_values(by = \"Value\", ascending = False).plot.bar(title = \"Feature Importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1 = []\n",
    "for pred in preds:\n",
    "    if pred < 0:\n",
    "        preds1.append(0)\n",
    "    else:\n",
    "        preds1.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subir = pd.DataFrame()\n",
    "subir['Opportunity_ID'] =X_test.reset_index()['Opportunity_ID']\n",
    "subir['target'] = preds1\n",
    "subir.sort_values('Opportunity_ID',inplace = True)\n",
    "subir = subir.drop_duplicates('Opportunity_ID',keep = 'last')\n",
    "subir.set_index('Opportunity_ID', inplace = True)\n",
    "subir.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = log_loss(y_test, preds1)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combinacion Random Forest Regressor con CATBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_final = RandomForestRegressor(random_state = 123, n_estimators = 1100, min_samples_leaf = 5)\n",
    "modelo_final.fit(X = X_train_prep1.drop(columns = \"Total_Amount\"), y = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'modelo_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d39466612fe4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mRFPredicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelo_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_prep1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Total_Amount\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'modelo_final' is not defined"
     ]
    }
   ],
   "source": [
    "RFPredicts = modelo_final.predict(X_test_prep1.drop(columns = \"Total_Amount\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = log_loss(y_test, RFPredicts)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalPreds = []\n",
    "for i in range(len(RFPredicts)):\n",
    "    value = (RFPredicts[i] + preds[i]) / 2\n",
    "    finalPreds.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = log_loss(y_test, finalPreds)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame_test = pd.read_csv( \"../Test/Test.csv\" )\n",
    "DataFrame_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DataFrame_test.loc[DataFrame_test['Total_Amount_Currency'] == 'JPY', 'Total_Amount'] = DataFrame_test['Total_Amount']*0.0096\n",
    "DataFrame_test.loc[DataFrame_test['Total_Amount_Currency'] == 'JPY', 'Total_Amount_Currency'] = 'USD'\n",
    "\n",
    "DataFrame_test.loc[DataFrame_test['Total_Amount_Currency'] == 'EUR', 'Total_Amount'] = DataFrame_test['Total_Amount']*1.17\n",
    "DataFrame_test.loc[DataFrame_test['Total_Amount_Currency'] == 'EUR', 'Total_Amount_Currency'] \n",
    "DataFrame_test.loc[DataFrame_test['Total_Amount_Currency'] == 'AUD', 'Total_Taxable_Amount'] = DataFrame_test['Total_Amount']*0.70\n",
    "DataFrame_test.loc[DataFrame_test['Total_Amount_Currency'] == 'AUD', 'Total_Taxable_Amount_Currency'] = 'USD'\n",
    "\n",
    "DataFrame_test.loc[DataFrame_test['Total_Amount_Currency'] == 'GBP', 'Total_Amount'] = DataFrame_test['Total_Amount']*1.29\n",
    "DataFrame_test.loc[DataFrame_test['Total_Amount_Currency'] == 'GBP', 'Total_Amount_Currency'] = 'USD'\n",
    "\n",
    "DataFrame_test['Opportunity_Created_Date'] = pd.to_datetime(DataFrame_test['Opportunity_Created_Date'],errors='coerce')\n",
    "\n",
    "DataFrame_test[\"Year Created\"] = DataFrame_test[\"Opportunity_Created_Date\"].dt.year\n",
    "DataFrame_test[\"Month Created\"] =DataFrame_test[\"Opportunity_Created_Date\"].dt.month\n",
    "DataFrame_test[\"Expensive\"] = np.where(DataFrame_test[\"Total_Amount\"] >= 80000, 1, 0)\n",
    "\n",
    "\n",
    "DataFrame_test = DataFrame_test.merge(entrenamiento_won_by_region, on = \"Region\")\n",
    "DataFrame_test[\"Años en entregar\"] = DataFrame_test[\"Delivery_Year\"] - DataFrame_test[\"Year Created\"]\n",
    "DataFrame_test[\"Total_Taxable_Amount\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame_test[\"Total_Amount\"] = np.log(DataFrame_test[\"Total_Amount\"])\n",
    "DataFrame_test = DataFrame_test[['Opportunity_ID', \"Total_Amount\", \"Años en entregar\",\"Month Created\", \"Product_Name\", \"Opportunity_Owner\"]]\n",
    "DataFrame_test = DataFrame_test.drop_duplicates('Opportunity_ID',keep = 'first')\n",
    "DataFrame_test.set_index('Opportunity_ID', inplace = True)\n",
    "DataFrame_test[\"Product_Name\"] = DataFrame_test[\"Product_Name\"].map(mean_encoded_product)\n",
    "DataFrame_test[\"Opportunity_Owner\"] = DataFrame_test[\"Opportunity_Owner\"].map(mean_encoded_owner)\n",
    "DataFrame_test[\"Source \"] = DataFrame_test[\"Source \"].map(mean_encoded_source)\n",
    "DataFrame_test[\"Account_Type\"] = DataFrame_test[\"Account_Type\"].map(mean_encoded_acc)\n",
    "DataFrame_test[\"Account_Name\"] = DataFrame_test[\"Account_Name\"].map(mean_encoded_accow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame_test[\"Product_Name\"].fillna(mean_encoded_product[\"Other\"], inplace = True)\n",
    "DataFrame_test[\"Opportunity_Owner\"].fillna(mean_encoded_owner[\"Other\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame_test[\"Account_Name\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame_test[\"Account_Name\"].fillna(mean_encoded_accow[\"Other\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame_test[\"Account_Name\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors = 2)\n",
    "test = pd.DataFrame(imputer.fit_transform(DataFrame_test), columns = DataFrame_test.columns, index = DataFrame_test.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = DataFrame_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se identifica el nobre de las columnas numéricas y categóricas\n",
    "cat_cols = DataFrame_test.select_dtypes(include=['object', 'category']).columns.to_list()\n",
    "numeric_cols = DataFrame_test.select_dtypes(include=['float64', 'int']).columns.to_list()\n",
    "\n",
    "# Se aplica one-hot-encoding solo a las columnas categóricas\n",
    "preprocessor = ColumnTransformer(\n",
    "                    [('onehot', OneHotEncoder(handle_unknown='ignore'), cat_cols)],\n",
    "                    remainder='passthrough'\n",
    "               )\n",
    "\n",
    "# Una vez que se ha definido el objeto ColumnTransformer, con el método fit()\n",
    "# se aprenden las transformaciones con los datos de entrenamiento y se aplican a\n",
    "# los dos conjuntos con transform(). Ambas operaciones a la vez con fit_transform().\n",
    "KaggleTest = preprocessor.fit_transform(DataFrame_test)\n",
    "\n",
    "\n",
    "#El resultado devuelto por ColumnTransformer es un numpy array, por lo que se pierden los nombres de las columnas. Es interesante poder inspeccionar cómo queda el set de datos tras el preprocesado en formato dataframe. Por defecto, OneHotEncoder ordena las nuevas columnas de izquierda a derecha por orden alfabético.\n",
    "\n",
    "# Convertir el output del ColumnTransformer en dataframe y añadir nombre columnas\n",
    "# ==============================================================================\n",
    "# Nombre de todas las columnas\n",
    "encoded_cat = preprocessor.named_transformers_['onehot'].get_feature_names(cat_cols)\n",
    "labels = np.concatenate([encoded_cat, numeric_cols])\n",
    "\n",
    "# Conversión a dataframe\n",
    "KaggleTest = pd.DataFrame(KaggleTest, columns=labels)\n",
    "KaggleTest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KaggleTest.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADAPredicts = adaModel.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATPredicts = model.predict(KaggleTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATPredicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFPredicts = modelo_final.predict(KaggleTest.drop(columns = \"Total_Amount\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalPreds = []\n",
    "for i in range(len(RFPredicts)):\n",
    "    value = (RFPredicts[i] + CATPredicts[i]) / 2\n",
    "    finalPreds.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalPreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subir = pd.DataFrame()\n",
    "subir['Opportunity_ID'] = DataFrame_test.reset_index()['Opportunity_ID']\n",
    "subir['target'] = ADAPredicts\n",
    "subir.sort_values('Opportunity_ID',inplace = True)\n",
    "subir = subir.drop_duplicates('Opportunity_ID',keep = 'last')\n",
    "subir.set_index('Opportunity_ID', inplace = True)\n",
    "subir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'subir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-5e87f1beee15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msubir\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'subir' is not defined"
     ]
    }
   ],
   "source": [
    "subir['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subir.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subir.to_csv('ADABoost7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = make_pipeline(StandardScaler(), svm.NuSVR())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_test)\n",
    "loss = log_loss(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = BernoulliNB()\n",
    "gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = gnb.predict(X_test)\n",
    "loss = log_loss(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr1 = BaggingRegressor(base_estimator=RandomForestRegressor(random_state=123, n_estimators = 1100),\n",
    "...                         n_estimators=10, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = regr1.predict(X_test)\n",
    "log_loss(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "regr = MLPRegressor(activation = 'relu',alpha = 0.2, beta_1 = 0.85, hidden_layer_sizes = (70,70,70), solver = 'adam', max_iter = 1000, random_state = 123).fit(X_train, y_train)\n",
    "pred = regr.predict(X_test)\n",
    "log_loss(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-07048468df5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mreg3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madaModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mereg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVotingRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'ada'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mereg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "reg1 = model\n",
    "reg3 = adaModel\n",
    "ereg = VotingRegressor(estimators=[('gb', reg1), ('ada', reg3)])\n",
    "\n",
    "ereg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = ereg.predict(X_test)\n",
    "log_loss(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ereg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(ereg, open(\"VotingRegressor.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VotingPred = adaModel.predict(DataFrame_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subir = pd.DataFrame()\n",
    "subir['Opportunity_ID'] = DataFrame_test.reset_index()['Opportunity_ID']\n",
    "subir['target'] = VotingPred\n",
    "subir.sort_values('Opportunity_ID',inplace = True)\n",
    "subir = subir.drop_duplicates('Opportunity_ID',keep = 'last')\n",
    "subir.set_index('Opportunity_ID', inplace = True)\n",
    "subir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subir.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subir.to_csv('AdaName.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV, LassoCV\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('ridge', adaModel),\n",
    "             ('lasso', ereg)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_estimator = GradientBoostingRegressor(\n",
    " n_estimators=25, subsample=0.5, min_samples_leaf=25, max_features=1,\n",
    "   random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StackingRegressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3d96b844d92b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m reg = StackingRegressor(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mestimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     final_estimator=final_estimator)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'StackingRegressor' is not defined"
     ]
    }
   ],
   "source": [
    "reg = StackingRegressor(\n",
    "...     estimators=estimators,\n",
    "...     final_estimator=final_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = reg.predict(X_test)\n",
    "log_loss(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> from sklearn.linear_model import LogisticRegression\n",
    ">>> from sklearn.naive_bayes import GaussianNB\n",
    ">>> from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "\n",
    ">>> clf2 = RandomForestClassifier(n_estimators=1100, random_state=1)\n",
    "clf3 = cat.CatBoostClassifier(learning_rate = 0.0075, verbose = True, random_seed = 123, num_boost_round = 1500, max_depth = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "regr1 = BaggingClassifier(base_estimator=RandomForestClassifier(random_state=123, n_estimators = 1100) ,n_estimators=50, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> eclf1 = VotingClassifier(estimators=[\n",
    "...         ('lr', regr1), ('rf', clf2), ('gnb', clf3)], voting='hard')\n",
    ">>> eclf1 = eclf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = eclf1.predict(X_train)\n",
    "log_loss(y_train, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
